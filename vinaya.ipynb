{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;33m2022-09-18 05:22:17\u001b[38;5;251m vin01m.mul.xml\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3.10\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from functions import transliterate_xml\n",
    "from timeis import timeis, yellow, line, tic, toc\n",
    "from clean_text import text_cleaner\n",
    "\n",
    "# print(f\"{timeis()} {line}\")\n",
    "# print(f\"{timeis()} {yellow}building database of vinaya\")\n",
    "# print(f\"{timeis()} {line}\")\n",
    "\n",
    "cst_dir = \"../Cst4/Xml/\"\n",
    "output_dir = \"output/\"\n",
    "# log_file = \"log/log.tsv\"\n",
    "# log = open(log_file, \"a\")\n",
    "\n",
    "file_list = [\n",
    "    \"vin01m.mul.xml\",\n",
    "    # \"vin02m1.mul.xml\",\n",
    "    # \"vin02m2.mul.xml\",\n",
    "    # \"vin02m3.mul.xml\",\n",
    "    # \"vin02m4.mul.xml\"\n",
    "]\n",
    "\n",
    "for file_name in file_list:\n",
    "\tprint(f\"{timeis()} {file_name}\")\n",
    "\n",
    "\t# transliterate the xml files into roman and save\n",
    "\twith open(f\"{cst_dir}{file_name}\", \"r\", encoding=\"UTF-16\") as f:\n",
    "\t\txml = f.read()\n",
    "\n",
    "\txml = transliterate_xml(xml)\n",
    "\n",
    "\twith open(f\"../Cst4/xml roman/{file_name}\", \"w\") as w:\n",
    "\t\tw.write(xml)\n",
    "\n",
    "\t# make the soup\n",
    "\tsoup = BeautifulSoup(xml, \"xml\")\n",
    "\n",
    "\t# remove all the \"pb\" tags\n",
    "\tpbs = soup.find_all(\"pb\")\n",
    "\tfor pb in pbs:\n",
    "\t\tpb.decompose()\n",
    "\n",
    "\t# remove all the notes\n",
    "\tnotes = soup.find_all(\"note\")\n",
    "\tfor note in notes:\n",
    "\t\tnote.decompose()\n",
    "\n",
    "\t# remove all the para tags\n",
    "\tpns = soup.find_all(\"p\")\n",
    "\tfor pn in pns:\n",
    "\t\tdel pn[\"n\"]\n",
    "\n",
    "\t# remove all the hi tags\n",
    "\this = soup.find_all(\"hi\")\n",
    "\tfor hi in his:\n",
    "\t\thi.unwrap()\n",
    "\t\n",
    "\twith open(f\"output/temp/{file_name}.xml\", \"w\") as w:\n",
    "\t\tw.write(soup.prettify())\n",
    "\n",
    "\t\t\n",
    "\t# - text cleaner\n",
    "\t# - find chatper title subhead\n",
    "\t# - list of all possible sentence beginning and endings\n",
    "\t# - find all inflections\n",
    "\n",
    "search_word = input(\"what are you looking for? \")\n",
    "search_sentence = re.compile(\n",
    "\tf\"(^|\\\\. |\\\\! |\\\\? )(.*?{search_word}.*?($|\\\\. |\\\\! |\\\\? ))\")\n",
    "\n",
    "\n",
    "nikaya = soup.find_all(\"p\", rend=\"nikaya\")[0].string\n",
    "book = soup.find_all(\"head\", rend=\"book\")[0].string\n",
    "if book == \"pārājikapāḷi\":\n",
    "\tbook_no = \"1.\"\n",
    "\n",
    "# kanda = div.head rend = \"chapter\"\n",
    "# sutta = p rend = \"title\"\n",
    "# subtitle = p rend = \"subhead\"\n",
    "\n",
    "result_counter = 1\n",
    "sutta_counter = 1\n",
    "sutta_counter = 1\n",
    "subtitle_count = 1\n",
    "\n",
    "kanda = \"\"\n",
    "sutta = \"\"\n",
    "subtitle = \"\"\n",
    "\n",
    "divs = soup.find_all(\"div\", type=\"kanda\")\n",
    "\n",
    "for div in divs:\n",
    "\n",
    "\t# get kanda name and number\n",
    "\tif div.head[\"rend\"] == \"chapter\":\n",
    "\t\tkanda = div.head.string\n",
    "\t\tsutta_counter = 1\n",
    "\t\tif kanda == \"verañjakaṇḍaṃ\":\n",
    "\t\t\tkanda_no = \"0.\"\n",
    "\t\telse:\n",
    "\t\t\tkanda_no = re.sub(\"^ \", \"\", kanda)\n",
    "\t\t\tkanda_no = re.sub(\"(^\\\\d*\\\\.)(.+)\", \"\\\\1\", kanda_no)\n",
    "\n",
    "\tparas = div.children\n",
    "\n",
    "\tfor para in paras:\n",
    "\n",
    "\t\t# get sutta name and number\n",
    "\t\tif \"title\" in str(para):\n",
    "\t\t\tif not re.findall(\"vaggo$\", para.string):\n",
    "\t\t\t\tsutta_name = para.string\n",
    "\t\t\t\tsubtitle_count = 1\n",
    "\t\t\t\tsubtitle = \"\"\n",
    "\n",
    "\t\t\t\tsutta_no = f\"{sutta_counter}.\"\n",
    "\t\t\t\tsutta_no = re.sub(\"(^\\\\d*\\\\.)(.+)\", \"\\\\1\", sutta_name)\n",
    "\t\t\t\tsutta_clean = re.sub(\"(^\\\\d*\\\\. )(.+)\", \"\\\\2\", sutta_name)\n",
    "\t\t\t\tsutta_counter +=1\n",
    "\n",
    "\t\tif \"subhead\" in str(para):\n",
    "\t\t\tsubtitle = para.string\n",
    "\t\t\tsubtitle_no = f\"{subtitle_count}.\"\n",
    "\t\t\tsubtitle_count += 1\n",
    "\n",
    "\t\ttext = para.get_text()\n",
    "\t\tresults = re.findall(search_sentence, text)\n",
    "\n",
    "\t\tfor result in results: \n",
    "\t\t\tresult = text_cleaner(result[1])\n",
    "\t\t\tif kanda != \"\":\n",
    "\t\t\t\t\n",
    "\t\t\t\t# quick link\n",
    "\t\t\t\tprint(f\"[{result_counter}]\\n\")\n",
    "\t\t\t\tprint(f\"VIN \", end=\"\")\n",
    "\t\t\t\tprint(f\"{book_no}\", end=\"\")\n",
    "\t\t\t\tprint(f\"{kanda_no}\", end=\"\")\n",
    "\t\t\t\tprint(f\"{sutta_no}\", end=\"\")\n",
    "\t\t\t\tif subtitle != \"\":\n",
    "\t\t\t\t\tprint(f\"{subtitle_no}\", end=\"\")\n",
    "\t\t\t\t\n",
    "\t\t\t\t# name of the book\n",
    "\t\t\t\tprint(f\"\\t{sutta_clean}\", end=\"\")\n",
    "\t\t\t\tif subtitle != \"\":\n",
    "\t\t\t\t\tprint(f\", {subtitle}\", end=\"\")\n",
    "\n",
    "\t\t\t\tprint(f\"\\t{result}\")\n",
    "\n",
    "\t\t\t\tprint(f\"({book} {kanda} {sutta_name} {subtitle})\\n\")\n",
    "\n",
    "\t\t\tresult_counter += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
